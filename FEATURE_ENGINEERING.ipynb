{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. **What is a parameter?**\n",
        "A **parameter** in machine learning refers to the internal variables or coefficients that a model learns from the training data. For example, in linear regression, the parameters are the weights (slope) and the intercept.\n",
        "\n",
        "### 2. **What is correlation?**\n",
        "**Correlation** is a statistical measure that indicates the strength and direction of a relationship between two variables. It ranges from -1 to 1:\n",
        "- A **positive correlation** means that as one variable increases, the other also increases.\n",
        "- A **negative correlation** means that as one variable increases, the other decreases.\n",
        "\n",
        "### 3. **What does negative correlation mean?**\n",
        "A **negative correlation** means that two variables move in opposite directions. For example, as temperature increases, the amount of heating required decreases.\n",
        "\n",
        "### 4. **Define Machine Learning. What are the main components in Machine Learning?**\n",
        "**Machine Learning** is a subset of artificial intelligence (AI) where algorithms learn patterns from data and make predictions or decisions based on that. The main components in machine learning include:\n",
        "- **Data**: The information that is fed into the model.\n",
        "- **Model**: The algorithm or mathematical structure that learns from the data.\n",
        "- **Features**: Variables or attributes of the data used by the model.\n",
        "- **Labels**: The target or output the model aims to predict.\n",
        "- **Learning Algorithm**: The method that allows the model to learn from the data.\n",
        "\n",
        "### 5. **How does loss value help in determining whether the model is good or not?**\n",
        "The **loss value** quantifies how far the model's predictions are from the actual values. A **lower loss** indicates that the model's predictions are closer to the real values, meaning the model is better. It helps in optimization by guiding adjustments during training.\n",
        "\n",
        "### 6. **What are continuous and categorical variables?**\n",
        "- **Continuous variables** are numerical variables that can take any value within a range, such as height or temperature.\n",
        "- **Categorical variables** are variables that represent distinct groups or categories, such as gender, type of car, or color.\n",
        "\n",
        "### 7. **How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "Common techniques to handle categorical variables include:\n",
        "- **One-Hot Encoding**: Creating binary columns for each category.\n",
        "- **Label Encoding**: Assigning a unique number to each category.\n",
        "- **Binary Encoding**: Similar to one-hot encoding but more compact for high cardinality variables.\n",
        "\n",
        "### 8. **What do you mean by training and testing a dataset?**\n",
        "- **Training dataset** is used to train the model, meaning the model learns the patterns and relationships.\n",
        "- **Testing dataset** is used to evaluate the model's performance on unseen data.\n",
        "\n",
        "### 9. **What is sklearn.preprocessing?**\n",
        "`sklearn.preprocessing` is a module in scikit-learn that provides tools for preprocessing data, such as scaling, encoding, and imputing missing values.\n",
        "\n",
        "### 10. **What is a Test set?**\n",
        "A **Test set** is a portion of the data that is held back from training and is used to evaluate the performance of the model after it has been trained.\n",
        "\n",
        "### 11. **How do we split data for model fitting (training and testing) in Python?**\n",
        "In Python, you can use `train_test_split` from `sklearn.model_selection` to split the data into training and testing sets:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 12. **How do you approach a Machine Learning problem?**\n",
        "Approaching a machine learning problem involves:\n",
        "1. **Understanding the problem** and defining the goal.\n",
        "2. **Data collection** and **exploratory data analysis (EDA)**.\n",
        "3. **Data preprocessing** (cleaning, transforming, scaling).\n",
        "4. **Model selection** and training.\n",
        "5. **Evaluation** using appropriate metrics.\n",
        "6. **Model tuning** and improvement.\n",
        "7. **Deployment**.\n",
        "\n",
        "### 13. **Why do we have to perform EDA before fitting a model to the data?**\n",
        "**Exploratory Data Analysis (EDA)** helps you understand the structure, patterns, and anomalies in your data. It informs you about data cleaning, feature engineering, and the choice of algorithms for modeling.\n",
        "\n",
        "### 14. **How can you find correlation between variables in Python?**\n",
        "You can use `pandas` `corr()` method to find the correlation between variables:\n",
        "```python\n",
        "import pandas as pd\n",
        "correlation = df.corr()\n",
        "```\n",
        "\n",
        "### 15. **What is causation? Explain the difference between correlation and causation with an example.**\n",
        "**Causation** refers to a cause-and-effect relationship where one event directly influences another. **Correlation** does not imply causation; it only indicates a statistical relationship.\n",
        "\n",
        "**Example**: A study shows a correlation between ice cream sales and drowning incidents. This doesnâ€™t mean that ice cream causes drowning; both are influenced by a third factor, like summer weather.\n",
        "\n",
        "### 16. **What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "An **Optimizer** in machine learning is an algorithm used to minimize the loss function by adjusting the model's parameters. Common optimizers include:\n",
        "- **Gradient Descent**: Iteratively adjusts parameters by moving in the direction of the steepest decrease in loss.\n",
        "- **Stochastic Gradient Descent (SGD)**: A variant of gradient descent that updates parameters using a single random sample per iteration.\n",
        "- **Adam**: Combines momentum and RMSProp to adjust the learning rate based on recent gradients.\n",
        "\n",
        "### 17. **What is sklearn.linear_model?**\n",
        "`sklearn.linear_model` is a module in scikit-learn that provides linear models for regression and classification, such as **LinearRegression**, **LogisticRegression**, and **Ridge** regression.\n",
        "\n",
        "### 18. **What does model.fit() do? What arguments must be given?**\n",
        "`model.fit(X, y)` trains the model on the input data `X` (features) and target `y`. The arguments that must be given are:\n",
        "- `X`: The input features.\n",
        "- `y`: The target variable.\n",
        "\n",
        "### 19. **What does model.predict() do? What arguments must be given?**\n",
        "`model.predict(X)` generates predictions based on the input features `X`. The argument is:\n",
        "- `X`: The input features for which you want predictions.\n",
        "\n",
        "### 20. **What is feature scaling? How does it help in Machine Learning?**\n",
        "**Feature scaling** is the process of normalizing or standardizing features so they have similar scales. It helps improve the performance of many machine learning models (like gradient descent) which are sensitive to the scale of input data.\n",
        "\n",
        "### 21. **How do we perform scaling in Python?**\n",
        "You can use `StandardScaler` or `MinMaxScaler` from `sklearn.preprocessing` to scale features:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_X = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "### 22. **What is sklearn.preprocessing?**\n",
        "`sklearn.preprocessing` is a module in scikit-learn that provides methods to preprocess data, such as scaling, encoding, and imputing missing values.\n",
        "\n",
        "### 23. **What is data encoding?**\n",
        "**Data encoding** is the process of converting categorical data into numerical form to make it usable for machine learning algorithms. Techniques include:\n",
        "- **One-Hot Encoding**.\n",
        "- **Label Encoding**.\n"
      ],
      "metadata": {
        "id": "_rnTJjdW4YD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU4zeTju4Wp5"
      },
      "outputs": [],
      "source": []
    }
  ]
}